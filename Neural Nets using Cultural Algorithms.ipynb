{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b43537b",
   "metadata": {},
   "source": [
    "# Neural Network Weight Optimisation Using Cultural Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1596ba05",
   "metadata": {},
   "source": [
    "## Tensorflow and PyGAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0a6800",
   "metadata": {},
   "source": [
    "### Importing Libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8b237c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import pygad\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from pygad.kerasga import KerasGA\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c77c3d",
   "metadata": {},
   "source": [
    "### Configuring GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1470aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "51028b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cf726d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "15a0519f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Experience  Income  Family  CCAvg  Education  Mortgage  \\\n",
       "0   25           1      49       4    1.6          1         0   \n",
       "1   45          19      34       3    1.5          1         0   \n",
       "2   39          15      11       1    1.0          1         0   \n",
       "3   35           9     100       1    2.7          2         0   \n",
       "4   35           8      45       4    1.0          2         0   \n",
       "\n",
       "   Securities Account  CD Account  Online  CreditCard  target  \n",
       "0                   1           0       0           0       0  \n",
       "1                   1           0       0           0       0  \n",
       "2                   0           0       0           0       0  \n",
       "3                   0           0       0           0       0  \n",
       "4                   0           0       0           1       0  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a122ffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df,columns = ['Education'],drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857540d7",
   "metadata": {},
   "source": [
    "### Loading and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b0bf8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target',axis = 1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "edee0e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3b182c",
   "metadata": {},
   "source": [
    "### Splitting it into train and test and converting target into categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "99ec0895",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=42,\n",
    "                                                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3053ace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np_utils.to_categorical(y_train,num_classes=2)\n",
    "y_test=np_utils.to_categorical(y_test,num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667084e3",
   "metadata": {},
   "source": [
    "### Defining a basic tensorflow ANN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9ebb23c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([tf.keras.layers.Dense(12,input_shape = (12,),activation = 'relu'),\n",
    "                    tf.keras.layers.Dense(8,activation = 'relu'),\n",
    "                    tf.keras.layers.Dense(16, activation = 'relu'),\n",
    "                    tf.keras.layers.Dense(8,activation = 'relu'),\n",
    "                    tf.keras.layers.Dense(2,activation = 'softmax')\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "92891958",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcb0a20",
   "metadata": {},
   "source": [
    "### Fitness function for the genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b6db8ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_func(solution, sol_idx):\n",
    "    global X_train, y_train, keras_ga, model\n",
    "    \n",
    "    model_weights_matrix = pygad.kerasga.model_weights_as_matrix(model = model,weights_vector = solution)\n",
    "    \n",
    "    model.set_weights(weights = model_weights_matrix)\n",
    "    \n",
    "    predictions = model.predict(X_train)\n",
    "    \n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    \n",
    "    solution_fitness = 1.0/(loss(y_train,predictions).numpy() + 0.0000000001)\n",
    "    \n",
    "    return solution_fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b666db59",
   "metadata": {},
   "source": [
    "### Acceptance Function for Cultural Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e40d87dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acceptance_function(population, fitness):\n",
    "    belief_space = population[fitness.index(max(fitness))]\n",
    "    return belief_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31fa667",
   "metadata": {},
   "source": [
    "### Influence Function for Cultural Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4c78edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def influence_function(belief_space,population):\n",
    "    sim = cosine_similarity(belief_space.reshape(1,-1),population)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd59977",
   "metadata": {},
   "source": [
    "### Select the solutions which have highest similarity to the belief space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a9c8e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parent_selection(sim,population):\n",
    "    # Get the indices of the two highest values using argsort\n",
    "    highest_indices = np.argsort(sim[0])[-2:]\n",
    "\n",
    "    # Get the values at the indices using fancy indexing\n",
    "    highest_values = sim[0][highest_indices]\n",
    "    parent_1 = population[highest_indices[0]]\n",
    "    parent_2 = population[highest_indices[1]]\n",
    "    return parent_1,parent_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f4a75b",
   "metadata": {},
   "source": [
    "### Apply Genetic Operators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "051c107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2):\n",
    "    \"\"\"\n",
    "    Performs a crossover operation between two parents, producing two new children.\n",
    "\n",
    "    Args:\n",
    "        parent1 (numpy.ndarray): The first parent.\n",
    "        parent2 (numpy.ndarray): The second parent.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of two children produced by crossover.\n",
    "    \"\"\"\n",
    "    # Determine the length of the parents and the crossover point.\n",
    "    length = parent1.shape[0]\n",
    "    crossover_point = np.random.randint(1, length - 1)\n",
    "\n",
    "    # Create the first child by combining the parents.\n",
    "    child1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "\n",
    "    # Create the second child by combining the parents in reverse order.\n",
    "    child2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))\n",
    "\n",
    "    return child1, child2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3643d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(array):\n",
    "    \"\"\"\n",
    "    Adds a randomly generated value to 15% of the elements in a numpy array.\n",
    "\n",
    "    Args:\n",
    "        array (numpy.ndarray): The input array.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array with mutations applied.\n",
    "    \"\"\"\n",
    "    # Determine the number of elements to mutate.\n",
    "    num_mutations = int(0.15 * array.size)\n",
    "\n",
    "    # Generate random indices for the elements to mutate.\n",
    "    mutation_indices = np.random.choice(array.size, size=num_mutations, replace=False)\n",
    "\n",
    "    # Add a random value to the selected elements.\n",
    "    array[mutation_indices] += np.random.randn(num_mutations)\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069d1c6a",
   "metadata": {},
   "source": [
    "### Keep the best members in the population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fc6f0d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_population(population,child1, child2):\n",
    "    population = np.vstack((population, child1))\n",
    "    population = np.vstack((population,child2))\n",
    "# Calculate the fitness of each solution in the population.\n",
    "    fitness_values = np.zeros((population.shape[0],))\n",
    "    for i in range(population.shape[0]):\n",
    "        fitness_values[i] = fitness_func(population[i], i)\n",
    "\n",
    "    # Sort the population by fitness.\n",
    "    sorted_indices = np.argsort(fitness_values)\n",
    "    sorted_population = population[sorted_indices]\n",
    "\n",
    "    # Return the top 10 elements.\n",
    "    return sorted_population[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f30f487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cultural_algorithm(population):\n",
    "    \n",
    "    fitness = []\n",
    "    for idx, solution in enumerate(population):\n",
    "        fitness.append(fitness_func(solution,idx))\n",
    "    \n",
    "    belief_space = acceptance_function(population,fitness)\n",
    "    similarity_score = influence_function(belief_space,population)\n",
    "    parent1,parent2 = parent_selection(sim,population)\n",
    "    child1,child2 = crossover(parent1, parent2)\n",
    "    child1 = mutation(child1)\n",
    "    child2 = mutation(child2)\n",
    "    population = prune_population(population,child1, child2)\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "059eaff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_final_weights(population):\n",
    "    fitness = []\n",
    "    for idx, solution in enumerate(population):\n",
    "        fitness.append(fitness_func(solution,idx))\n",
    "    model_weights_matrix = pygad.kerasga.model_weights_as_matrix(model = model,weights_vector = population[fitness.index(max(fitness))])\n",
    "    \n",
    "    model.set_weights(weights = model_weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "142729a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shapes of the model's weights\n",
    "weights_shapes = [w.shape for w in model.get_weights()]\n",
    "\n",
    "# Compute the total number of weights\n",
    "num_weights = np.sum([np.prod(s) for s in weights_shapes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6032fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "population = np.random.uniform(size = (10,num_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8927a5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 408us/step\n",
      "92/92 [==============================] - 0s 390us/step\n",
      "92/92 [==============================] - 0s 365us/step\n",
      "92/92 [==============================] - 0s 374us/step\n",
      "92/92 [==============================] - 0s 382us/step\n",
      "92/92 [==============================] - 0s 352us/step\n",
      "92/92 [==============================] - 0s 370us/step\n",
      "92/92 [==============================] - 0s 391us/step\n",
      "92/92 [==============================] - 0s 370us/step\n",
      "92/92 [==============================] - 0s 360us/step\n",
      "92/92 [==============================] - 0s 369us/step\n",
      "92/92 [==============================] - 0s 359us/step\n",
      "92/92 [==============================] - 0s 369us/step\n",
      "92/92 [==============================] - 0s 376us/step\n",
      "92/92 [==============================] - 0s 369us/step\n",
      "92/92 [==============================] - 0s 372us/step\n",
      "92/92 [==============================] - 0s 401us/step\n",
      "92/92 [==============================] - 0s 381us/step\n",
      "92/92 [==============================] - 0s 370us/step\n",
      "92/92 [==============================] - 0s 364us/step\n",
      "92/92 [==============================] - 0s 362us/step\n",
      "92/92 [==============================] - 0s 376us/step\n",
      "92/92 [==============================] - 0s 383us/step\n",
      "92/92 [==============================] - 0s 397us/step\n",
      "92/92 [==============================] - 0s 384us/step\n",
      "92/92 [==============================] - 0s 483us/step\n",
      "92/92 [==============================] - 0s 376us/step\n",
      "92/92 [==============================] - 0s 370us/step\n",
      "92/92 [==============================] - 0s 396us/step\n",
      "92/92 [==============================] - 0s 397us/step\n",
      "92/92 [==============================] - 0s 393us/step\n",
      "92/92 [==============================] - 0s 390us/step\n",
      "92/92 [==============================] - 0s 382us/step\n",
      "92/92 [==============================] - 0s 384us/step\n",
      "92/92 [==============================] - 0s 415us/step\n",
      "92/92 [==============================] - 0s 381us/step\n",
      "92/92 [==============================] - 0s 365us/step\n",
      "92/92 [==============================] - 0s 366us/step\n",
      "92/92 [==============================] - 0s 356us/step\n",
      "92/92 [==============================] - 0s 357us/step\n",
      "92/92 [==============================] - 0s 351us/step\n",
      "92/92 [==============================] - 0s 358us/step\n",
      "92/92 [==============================] - 0s 383us/step\n",
      "92/92 [==============================] - 0s 402us/step\n",
      "92/92 [==============================] - 0s 358us/step\n",
      "92/92 [==============================] - 0s 375us/step\n",
      "92/92 [==============================] - 0s 371us/step\n",
      "92/92 [==============================] - 0s 350us/step\n",
      "92/92 [==============================] - 0s 379us/step\n",
      "92/92 [==============================] - 0s 350us/step\n",
      "92/92 [==============================] - 0s 378us/step\n",
      "92/92 [==============================] - 0s 360us/step\n",
      "92/92 [==============================] - 0s 365us/step\n",
      "92/92 [==============================] - 0s 364us/step\n",
      "92/92 [==============================] - 0s 365us/step\n",
      "92/92 [==============================] - 0s 361us/step\n",
      "92/92 [==============================] - 0s 377us/step\n",
      "92/92 [==============================] - 0s 382us/step\n",
      "92/92 [==============================] - 0s 364us/step\n",
      "92/92 [==============================] - 0s 364us/step\n",
      "92/92 [==============================] - 0s 374us/step\n",
      "92/92 [==============================] - 0s 367us/step\n",
      "92/92 [==============================] - 0s 371us/step\n",
      "92/92 [==============================] - 0s 362us/step\n",
      "92/92 [==============================] - 0s 372us/step\n",
      "92/92 [==============================] - 0s 369us/step\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    population = cultural_algorithm(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "668adcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 447us/step - loss: 0.0000e+00 - accuracy: 0.9437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.9437109231948853]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu]",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
